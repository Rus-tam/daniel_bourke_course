{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ee29c16a-20fe-4c39-bf70-ef0fa60df4f7",
   "metadata": {},
   "source": [
    "# Transfer Learning with TensorFlow Part 1: Feature Extraction\n",
    "\n",
    "Transfer learning is leveraging a working model's existing architecture and learned patterns for our own problems.\n",
    "\n",
    "There are two main benefits:\n",
    "\n",
    "1. Can leverage an existing neural network architecture proven to work on problems similar to our own.\n",
    "2. Can leverage a working neural network architecture which has already learned patterns on similar data to our own, then we can adapt those patterns to our own data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b10682ed-9f30-4c35-9b66-e22f291c8d8b",
   "metadata": {},
   "source": [
    "## Downloading and becoming one with the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e2887383-d74f-458b-8139-85cc3f1de30c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get data (10% of 10 food classes from Food10)\n",
    "import requests\n",
    "import zipfile\n",
    "import io\n",
    "# Download the zip file using requests\n",
    "\n",
    "url = \"https://storage.googleapis.com/ztm_tf_course/food_vision/10_food_classes_10_percent.zip\"\n",
    "response = requests.get(url)\n",
    "# Unzip the file in memory and extract it\n",
    "\n",
    "with zipfile.ZipFile(io.BytesIO(response.content)) as zip_ref:\n",
    "    zip_ref.extractall(\"pizza_steak\")  # Extract to a folder called 'pizza_steak'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e995ceb4-435f-4263-9a58-b4abd0fc1d2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there are 2 directories and 0 images in '../data/10_food_classes_10_percent/'\n",
      "there are 10 directories and 0 images in '../data/10_food_classes_10_percent/test'\n",
      "there are 0 directories and 250 images in '../data/10_food_classes_10_percent/test\\chicken_curry'\n",
      "there are 0 directories and 250 images in '../data/10_food_classes_10_percent/test\\chicken_wings'\n",
      "there are 0 directories and 250 images in '../data/10_food_classes_10_percent/test\\fried_rice'\n",
      "there are 0 directories and 250 images in '../data/10_food_classes_10_percent/test\\grilled_salmon'\n",
      "there are 0 directories and 250 images in '../data/10_food_classes_10_percent/test\\hamburger'\n",
      "there are 0 directories and 250 images in '../data/10_food_classes_10_percent/test\\ice_cream'\n",
      "there are 0 directories and 250 images in '../data/10_food_classes_10_percent/test\\pizza'\n",
      "there are 0 directories and 250 images in '../data/10_food_classes_10_percent/test\\ramen'\n",
      "there are 0 directories and 250 images in '../data/10_food_classes_10_percent/test\\steak'\n",
      "there are 0 directories and 250 images in '../data/10_food_classes_10_percent/test\\sushi'\n",
      "there are 10 directories and 0 images in '../data/10_food_classes_10_percent/train'\n",
      "there are 0 directories and 75 images in '../data/10_food_classes_10_percent/train\\chicken_curry'\n",
      "there are 0 directories and 75 images in '../data/10_food_classes_10_percent/train\\chicken_wings'\n",
      "there are 0 directories and 75 images in '../data/10_food_classes_10_percent/train\\fried_rice'\n",
      "there are 0 directories and 75 images in '../data/10_food_classes_10_percent/train\\grilled_salmon'\n",
      "there are 0 directories and 75 images in '../data/10_food_classes_10_percent/train\\hamburger'\n",
      "there are 0 directories and 75 images in '../data/10_food_classes_10_percent/train\\ice_cream'\n",
      "there are 0 directories and 75 images in '../data/10_food_classes_10_percent/train\\pizza'\n",
      "there are 0 directories and 75 images in '../data/10_food_classes_10_percent/train\\ramen'\n",
      "there are 0 directories and 75 images in '../data/10_food_classes_10_percent/train\\steak'\n",
      "there are 0 directories and 75 images in '../data/10_food_classes_10_percent/train\\sushi'\n"
     ]
    }
   ],
   "source": [
    "# How many images in each folder?\n",
    "import os\n",
    "\n",
    "# Walk through 10 percent data directory and list number of files\n",
    "for dirpath, dirnames, filenames in os.walk('../data/10_food_classes_10_percent/'):\n",
    "    print(f\"there are {len(dirnames)} directories and {len(filenames)} images in '{dirpath}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c4ccd0b-4cf1-4404-ba31-1003fd89017a",
   "metadata": {},
   "source": [
    "## Creating data loader (preparing the data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "920af032-38c0-4822-b4d0-2b55ed2c1fb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 750 files belonging to 10 classes.\n",
      "Found 2500 files belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
    "\n",
    "IMAGE_SHAPE = (224, 224)\n",
    "BATCH_SIZE = 32\n",
    "train_dir = \"../data/10_food_classes_10_percent/train/\"\n",
    "test_dir = \"../data/10_food_classes_10_percent/test/\"\n",
    "\n",
    "train_data = image_dataset_from_directory(directory=train_dir,\n",
    "                                          label_mode=\"categorical\",\n",
    "                                          batch_size=BATCH_SIZE,\n",
    "                                          image_size=IMAGE_SHAPE,\n",
    "                                          seed=42)\n",
    " \n",
    "test_data = image_dataset_from_directory(directory=test_dir,\n",
    "                                         label_mode=\"categorical\",\n",
    "                                         batch_size=BATCH_SIZE,\n",
    "                                         image_size=IMAGE_SHAPE,\n",
    "                                         seed=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4b67055-1012-43e8-9e52-039c4a75c28d",
   "metadata": {},
   "source": [
    "## Setting up callbacks (things to run while our model trains)\n",
    "\n",
    "Callbacks are extra functionality you can add to your models to be performed during or after training. Some of the most popular callbacks:\n",
    "\n",
    "* Tracking experiments with the TensorBoard callback\n",
    "* Model checkpoin with the ModelCheckpoint callback\n",
    "* Stopping a model from training (before it trains too long and overfits) with the EarlyStopping callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "df9c72fa-783b-4df9-96d9-78388cf0a6a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create TensorBoard callback (functionized because we need to create a new one for each model)\n",
    "import datetime\n",
    "\n",
    "def create_tensorboard_callback(dir_name, experiment_name):\n",
    "    log_dir = dir_name + \"/\" + experiment_name + \"/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "    tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir)\n",
    "    print(f\"Saving TensorBoard log files to: {log_dir}\")\n",
    "\n",
    "    return tensorboard_callback"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5cd3516-2bfa-4c53-9f22-66fbcf86b6b5",
   "metadata": {},
   "source": [
    "## Creating models using TensorFlow Hub\n",
    "\n",
    "In the past we've use TensorFlow to create our own models layers by layer from scratch.\n",
    "\n",
    "Now we're going to do a similar process, except the majority of our model's layers are going to come fro TensorFlow Hub.\n",
    "\n",
    "We can access pretrained models on: https://tfhub.dev/\n",
    "\n",
    "Browsing the TensorFlow Hub page and sorting for image classification, we found the following feature vector model link:\n",
    "https://www.kaggle.com/models/google/resnet-v2/tensorFlow2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "982dd8b9-e56a-44bf-97be-7a010aaa2780",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
